# ğŸš€ Scalable MLflow for Large-Scale AI Experiment Tracking with Knative & Kubernetes

## Overview
This repository provides a **fully serverless, Kubernetes-native MLflow setup** for tracking **AI experiments at scale**, including **LLM fine-tuning** and large-scale **ML model experimentation**. By leveraging **Knative and Kubernetes**, we enable **on-demand, auto-scaled MLflow instances**, handling thousands of experiments across **distributed AI workflows**.

ğŸ”¥ **Key Features:**
- **Serverless MLflow** â€“ Deploy MLflow tracking servers on-demand with **Knative & Kubernetes**.
- **AWS EFS for Persistent Storage** â€“ Ensures logs, models, and metadata are stored securely and persist across sessions.
- **Massive Scalability** â€“ Simulates **10K simultaneous MLflow instances** across **150 Kubernetes nodes**.
- **Locust Load Testing** â€“ Stress tests MLflowâ€™s ability to **handle thousands of AI experiments in parallel**.
- **Designed for LLM Experimentation** â€“ Optimized for **fine-tuning and tracking large-scale AI model experiments**.
- **Multi-Cloud Ready** â€“ Although tested on **AWS EKS**, it can be adapted to **GKE, AKS, or on-prem K8s clusters**.


---

## ğŸ“Œ Architecture & Deployment
### **1ï¸âƒ£ MLflow on Knative & Kubernetes**
- MLflow instances **scale dynamically** using **Knative's event-driven model**.
- Each MLflow instance runs **ephemerally**, but logs are persisted in **AWS EFS**.
- Serverless requests trigger **instant MLflow tracking servers**, reducing compute waste.

### **2ï¸âƒ£ Persistent Experiment Storage with AWS EFS**
- MLflow artifacts, logs, and model metadata are stored on **AWS Elastic File System (EFS)**.
- Ensures that experiment history remains accessible across **restarts and scale events**.

### **3ï¸âƒ£ Locust Load Testing for Scale Validation**
- Simulates **10,000 MLflow tracking instances** to test robustness.
- Runs across **150 Kubernetes nodes**, validating large-scale experiment tracking.
- Provides real-time **latency, throughput, and resource utilization metrics**.

---

## ğŸš€ Quick Start Guide
### **1ï¸âƒ£ Clone the Repository**
```sh
git clone https://github.com/vinay-jayanna/scalable-mlflow-knative.git
cd scalable-mlflow-knative
```

### **2ï¸âƒ£ Install Dependencies & Set Up Environment**
```sh
kubectl apply -f src/installs/efs/efs-pv-pvc.yaml
kubectl apply -f src/installs/efs/mlflow-efs-main.yaml
```

### **3ï¸âƒ£ Deploy MLflow on Kubernetes with Knative**
```sh
kubectl apply -f src/deploy/mlflow-apefs-0001.yaml
kubectl apply -f src/deploy/mlflow-apefs-0002.yaml
```

### **4ï¸âƒ£ Load Test with Locust**
Run a large-scale test simulating **10K concurrent MLflow instances**:
```sh
locust -f src/test/111-locustfile.py --headless -u 10000 -r 500
```

---

## ğŸ”¥ Why Use This?
ğŸ”¹ **AI Experimentation at Scale** â€“ Handles massive AI workloads with dynamic resource allocation.  
ğŸ”¹ **Optimized for LLM Training & Fine-Tuning** â€“ Track multiple training runs efficiently.  
ğŸ”¹ **Zero Waste, Cost-Efficient** â€“ Scale MLflow servers only when needed, reducing costs.  
ğŸ”¹ **Persistent Tracking Across Sessions** â€“ Never lose experiment logs, models, or metadata.  
ğŸ”¹ **Multi-Cloud Flexibility** â€“ Adaptable to AWS, GCP, Azure, or on-prem Kubernetes.  

---

## ğŸ“š Additional Resources
- **ğŸ“– Installation Steps:** [`tutorial/install_steps.txt`](tutorial/install_steps.txt)
- **ğŸš€ Deployment Steps:** [`tutorial/deploy_steps.txt`](tutorial/deploy_steps.txt)
- **ğŸ“œ AWS EFS Configuration:** [`src/installs/efs/efs-pv-pvc.yaml`](src/installs/efs/efs-pv-pvc.yaml)
- **ğŸ“¦ MLflow Knative Deployment:** [`src/deploy/mlflow-apefs-0001.yaml`](src/deploy/mlflow-apefs-0001.yaml)
- **ğŸ“Š Load Testing with Locust:** [`src/test/111-locustfile.py`](src/test/111-locustfile.py)


